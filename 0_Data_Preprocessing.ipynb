{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6fc271-93ff-4d24-8879-27af3bf07c66",
   "metadata": {},
   "source": [
    "# Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "106b9991-ca19-410a-b1d1-e0201f3c22c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing packages\n",
    "import pickle\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "import os\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76c49c34-4fff-470d-b323-306a793dd9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"alexuw/pooledImages/\"\n",
    "filenames = next(walk(images_dir), (None, None, []))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9981abd-e734-4985-8bce-d6b4ef5f0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(filenames, columns=[\"path\"])\n",
    "bad_samples_reference = pd.read_csv(\"alexuw/bad_samples_reference.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fbdca33-2f8e-47a7-a2cb-f2c4a46e0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_text = {}\n",
    "with open(\"alexuw/alexuw_wordList.txt\", encoding=\"utf-16\", errors='ignore') as f:\n",
    "    for num, line in enumerate(f, 1):\n",
    "        words_text[int(num)] = line.rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b498bd2-b82f-41e1-8be0-4fdf56e3ce23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35c6ee4f-b300-4c94-8056-17020852b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"img_id\"] = df[\"path\"].apply(lambda x: int(x.rstrip(\".jpg\").split('-')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e9dd9c5-cd97-4a26-a09d-2b09db9b26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"path\"] = df[\"path\"].apply(lambda x: images_dir+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e1628f4-d30c-45b0-91e2-574b25f9bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word\"] = df[\"img_id\"].apply(lambda x: words_text[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2133385-c145-4062-b8c0-a4dac3b0aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(list(\"\".join(df[\"word\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf202d2-1e22-49ad-aa25-e1b2a416b560",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3c2836e-1386-4d35-84ed-0f872ed8d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample = namedtuple('Sample', 'gt_text, file_path')\n",
    "Batch = namedtuple('Batch', 'imgs, gt_texts, batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64052c77-ee0a-48cb-8b57-8e92a5d9501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for image in df.to_dict('records'):\n",
    "    samples.append(Sample(image[\"word\"], image[\"path\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4606e8c7-6519-4917-8d7a-ef364e222781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self,\n",
    "                 data_dir: Path,\n",
    "                 batch_size: int,\n",
    "                 chars: set,\n",
    "                 samples: list,\n",
    "                 data_split: float = 0.95) -> None:\n",
    "        \"\"\"Loader for dataset.\"\"\"\n",
    "\n",
    "        assert os.path.exists(data_dir)\n",
    "\n",
    "        self.data_augmentation = False\n",
    "        self.curr_idx = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.samples = samples\n",
    "        self.chars = chars\n",
    "        \n",
    "\n",
    "        # split into training and validation set: 95% - 5%\n",
    "        split_idx = int(data_split * len(self.samples))\n",
    "        self.train_samples = self.samples[:split_idx]\n",
    "        self.validation_samples = self.samples[split_idx:]\n",
    "\n",
    "        # put words into lists\n",
    "        self.train_words = [x.gt_text for x in self.train_samples]\n",
    "        self.validation_words = [x.gt_text for x in self.validation_samples]\n",
    "\n",
    "        # start with train set\n",
    "        self.train_set()\n",
    "\n",
    "        # list of all chars in dataset\n",
    "        self.char_list = sorted(list(self.chars))\n",
    "\n",
    "    def train_set(self) -> None:\n",
    "        \"\"\"Switch to randomly chosen subset of training set.\"\"\"\n",
    "        self.data_augmentation = True\n",
    "        self.curr_idx = 0\n",
    "        random.shuffle(self.train_samples)\n",
    "        self.samples = self.train_samples\n",
    "        self.curr_set = 'train'\n",
    "\n",
    "    def validation_set(self) -> None:\n",
    "        \"\"\"Switch to validation set.\"\"\"\n",
    "        self.data_augmentation = False\n",
    "        self.curr_idx = 0\n",
    "        self.samples = self.validation_samples\n",
    "        self.curr_set = 'val'\n",
    "\n",
    "    def get_iterator_info(self) -> Tuple[int, int]:\n",
    "        \"\"\"Current batch index and overall number of batches.\"\"\"\n",
    "        if self.curr_set == 'train':\n",
    "            num_batches = int(np.floor(len(self.samples) / self.batch_size))  # train set: only full-sized batches\n",
    "        else:\n",
    "            num_batches = int(np.ceil(len(self.samples) / self.batch_size))  # val set: allow last batch to be smaller\n",
    "        curr_batch = self.curr_idx // self.batch_size + 1\n",
    "        return curr_batch, num_batches\n",
    "\n",
    "    def has_next(self) -> bool:\n",
    "        \"\"\"Is there a next element?\"\"\"\n",
    "        if self.curr_set == 'train':\n",
    "            return self.curr_idx + self.batch_size <= len(self.samples)  # train set: only full-sized batches\n",
    "        else:\n",
    "            return self.curr_idx < len(self.samples)  # val set: allow last batch to be smaller\n",
    "\n",
    "    def _get_img(self, i: int) -> np.ndarray:\n",
    "        img = cv2.imread(self.samples[i].file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_next(self) -> Batch:\n",
    "        \"\"\"Get next element.\"\"\"\n",
    "        batch_range = range(self.curr_idx, min(self.curr_idx + self.batch_size, len(self.samples)))\n",
    "\n",
    "        imgs = [self._get_img(i) for i in batch_range]\n",
    "        gt_texts = [self.samples[i].gt_text for i in batch_range]\n",
    "\n",
    "        self.curr_idx += self.batch_size\n",
    "        return Batch(imgs, gt_texts, len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07d3c7a9-9256-44ef-a784-6c1fd69b0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data_dir=images_dir,\n",
    "                    batch_size=64,\n",
    "                    samples=samples,\n",
    "                    chars=chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95b1f397-d425-42bb-ac2c-8a6b751ee898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723592cb-4ef7-4325-ab83-89cc343bbf34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
